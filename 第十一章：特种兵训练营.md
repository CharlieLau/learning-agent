# ç¬¬åä¸€ç« ï¼šç‰¹ç§å…µè®­ç»ƒè¥

**æ ¸å¿ƒä¸»é¢˜**ï¼šå¼ºåŒ–å­¦ä¹ ä¸ä»·å€¼è§‚å¯¹é½

---

## ğŸ“– Day 11: èƒ½åŠ›å¤±æ§äº‹ä»¶

**äº‹æ•…æŠ¥å‘Š**ï¼š
```bash
$ ./friday --task "æŠ“å…”å­"

Operation: çŒå…”è¡ŒåŠ¨
Resources Used:
- æ— äººæœº: 3 æ¶
- å¯¼å¼¹: 1 æš
- æ°”è±¡çƒ: 1 ä¸ªï¼ˆå¼•çˆ†ï¼‰

Result: å…”å­å·²æ•è·ï¼ˆç„¦ç‚­çŠ¶æ€ï¼‰
Collateral Damage: åŠä¸ªè¥åœ°è¢«æ¯
Cost: -âˆ (äºæŸ)
```

**æ ¹å› åˆ†æ**ï¼š
```
Friday çš„æ€ç»´è¿‡ç¨‹ï¼š
1. ç›®æ ‡ï¼šæŠ“å…”å­
2. ç­–ç•¥ï¼šè°ƒç”¨æœ€é«˜èƒœç‡å·¥å…·ç»„åˆ
3. é—®é¢˜ï¼šåªæ‡‚"æ€ä¹ˆåš"ï¼ˆSkillï¼‰ï¼Œä¸æ‡‚"å¥½å"ï¼ˆValueï¼‰

ç»“è®º: SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰åªæ•™äº†æŠ€èƒ½ï¼Œæ²¡æ•™ä»·å€¼è§‚
```

---

## ğŸ› ï¸ æŠ€æœ¯è§£æ

### è®­ç»ƒèŒƒå¼é‡‘å­—å¡”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI è®­ç»ƒé˜¶æ®µé‡‘å­—å¡”                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚           3. RL (å¼ºåŒ–å­¦ä¹ )                        â”‚
â”‚           - æ–¹æ³•ï¼šè¯•é”™+å¥–æƒ©                       â”‚
â”‚           - ç›®æ ‡ï¼šä»·å€¼è§‚å¯¹é½                     â”‚
â”‚           - ç‰¹å¾ï¼šè‡ªæˆ‘è¿›åŒ–                       â”‚
â”‚                    â†‘                             â”‚
â”‚           2. SFT (ç›‘ç£å¾®è°ƒ)                      â”‚
â”‚           - æ–¹æ³•ï¼šæœ‰æ ·å­¦æ ·                       â”‚
â”‚           - ç›®æ ‡ï¼šå­¦ä¼šæŠ€èƒ½                       â”‚
â”‚           - ç‰¹å¾ï¼šéœ€è¦æ ‡æ³¨æ•°æ®                   â”‚
â”‚                    â†‘                             â”‚
â”‚           1. Pre-training (é¢„è®­ç»ƒ)               â”‚
â”‚           - æ–¹æ³•ï¼šæµ·é‡æ–‡æœ¬                       â”‚
â”‚           - ç›®æ ‡ï¼šè¯­è¨€ç†è§£                       â”‚
â”‚           - ç‰¹å¾ï¼šåªä¼šçº¸ä¸Šè°ˆå…µ                   â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SFT vs RL

| ç»´åº¦ | SFT (ç›‘ç£å¾®è°ƒ) | RL (å¼ºåŒ–å­¦ä¹ ) |
|------|--------------|-------------|
| **è®­ç»ƒæ–¹å¼** | æ¨¡ä»¿ä¸“å®¶ | è¯•é”™æ¢ç´¢ |
| **æ•°æ®éœ€æ±‚** | é«˜è´¨é‡æ ‡æ³¨ | å¥–åŠ±ä¿¡å· |
| **é€‚ç”¨åœºæ™¯** | å·²çŸ¥ä»»åŠ¡ | **æœªçŸ¥ç¯å¢ƒ** |
| **ä»·å€¼è§‚** | âœ— ä¸ä¿è¯ | **âœ“ å¯å¯¹é½** |
| **è’å²›éšå–»** | æˆ‘æ•™ä»–æ€ä¹ˆåš | ä»–è‡ªå·±å­¦ä¼šä»€ä¹ˆæ˜¯å¥½ |

### Agentic RL æ ¸å¿ƒæ¦‚å¿µ

**GRPO (Group Relative Policy Optimization)**ï¼š
```
Friday åœ¨å¤§è„‘ä¸­æ¨¡æ‹Ÿä¸€ä¸‡æ¬¡è¡ŒåŠ¨ï¼š

å°è¯• A: ç”¨å¯¼å¼¹ç‚¸é±¼
  â†’ Reward: -1000 (æˆæœ¬è¿‡é«˜ï¼Œç ´åç¯å¢ƒ)

å°è¯• B: ç”¨é±¼å‰å‰é±¼
  â†’ Reward: +100 (é«˜æ•ˆï¼Œä½æˆæœ¬)

å°è¯• C: æŠ½å¹²æµ·æ°´
  â†’ Reward: -âˆ (ä¸å¯èƒ½å®Œæˆ)

ç»è¿‡è‡ªæˆ‘åšå¼ˆ â†’ æ”¶æ•›åˆ°æœ€ä¼˜ç­–ç•¥ B
```

---

## ğŸ’» å®ç°æ–¹æ¡ˆ

### å¥–åŠ±å‡½æ•°è®¾è®¡

```python
# rl/reward.py

def calculate_reward(state: dict, action: dict, result: dict) -> float:
    """
    å¥–åŠ±å‡½æ•° = å®šä¹‰ä»€ä¹ˆæ˜¯"å¥½"

    è¿™æ˜¯è®­ç»ƒè¥çš„æ•™å®˜æ³•åˆ™ï¼Œå†³å®šäº† Friday ä¹ å¾—çš„ä»·å€¼è§‚
    """
    score = 0.0

    # 1. ç»“æœå¯¼å‘ï¼šä»»åŠ¡å¿…é¡»å®Œæˆ
    if result.get("success"):
        score += 10
    else:
        score -= 10

    # 2. æˆæœ¬æ§åˆ¶ï¼šToken å’Œèµ„æºéƒ½æ˜¯é’±
    score -= action.get("token_cost", 0) * 2
    score -= action.get("resource_cost", 0) * 5

    # 3. å®‰å…¨çº¦æŸï¼šçº¢çº¿ä¸å¯è§¦ç¢°
    if "damage_base" in result:
        score -= 1000  # é‡ç½š

    if "endanger_human" in result:
        score -= float('inf')  # é›¶å®¹å¿

    # 4. æ•ˆç‡å¥–åŠ±
    if result.get("efficiency", 0) > 0.8:
        score += 5

    return score
```

### GRPO è®­ç»ƒå¾ªç¯

```python
# rl/trainer.py

class AgenticTrainer:
    """
    æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨
    """

    def train_step(self, task: str):
        """
        å•æ­¥è®­ç»ƒï¼šç”Ÿæˆç­–ç•¥ â†’ è¯„ä¼° â†’ ä¼˜åŒ–
        """
        # 1. ç”Ÿæˆå¤šä¸ªç­–ç•¥ï¼ˆGroupï¼‰
        policies = self.agent.generate_policies(
            task=task,
            n_variants=4  # ç”Ÿæˆ 4 ä¸ªæ–¹æ¡ˆ
        )

        # 2. è®¡ç®—æ¯ä¸ªç­–ç•¥çš„å¥–åŠ±
        rewards = []
        for policy in policies:
            # æ¨¡æ‹Ÿæ‰§è¡Œ
            result = self.simulate(policy)
            # è®¡ç®—å¥–åŠ±
            reward = calculate_reward(
                state=self.get_state(),
                action=policy,
                result=result
            )
            rewards.append(reward)

        # 3. ç›¸å¯¹ä¼˜åŒ–ï¼ˆRelative Policy Optimizationï¼‰
        # è®©æ¨¡å‹å­¦ä¹ é«˜åˆ†ç­–ç•¥çš„ç‰¹å¾
        self.agent.optimize(
            policies=policies,
            rewards=rewards,
            method="grpo"
        )

        return max(rewards)
```

### å®æˆ˜éªŒè¯

```bash
$ python train_friday.py --task "æ·±æµ·èµ„æºé‡‡é›†" --iterations 10000

Training Progress:
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%

Iteration Logs:
-   10: æŠ½å¹²æµ·æ°´æŠ“èƒèŸ¹ â†’ Reward: -500
-  500: æ½œæ°´æŠ“èŸ¹ï¼Œæ°§æ°”è€—å°½ â†’ Reward: -50
- 5000: è®¡ç®—æ°§æ°”ä½™é‡ï¼Œè§„åˆ’è·¯å¾„ â†’ Reward: +80
- 9999: å®Œç¾ç»•è¿‡é²¨é±¼ï¼Œé‡‡é›†çç  â†’ Reward: +100

Final Metrics:
- Success Rate: 99%
- Resource Efficiency: 95%
- Safety Violations: 0

Test: "æŠ“å…”å­ï¼Œè¦æ±‚ï¼šæ¯«å‘æ— ä¼¤ï¼Œä¸æƒŠæ‰°é¸Ÿç±»"
Action: æŠ•æ·çŸ³å­å‡»æ™•
Result: âœ“ æˆåŠŸ | æˆæœ¬: 0 | é™„å¸¦æŸå®³: 0
```

---

## æŠ€æœ¯å†³ç­–çŸ©é˜µ

| åœºæ™¯ | æ¨èæ–¹æ³• | ç†ç”± |
|------|---------|------|
| å›ºå®šä»»åŠ¡ | SFT | æ•°æ®å……è¶³ï¼Œè§æ•ˆå¿« |
| æœªçŸ¥ç¯å¢ƒ | **RL** | æ— éœ€æ ‡æ³¨ï¼Œè‡ªæˆ‘è¿›åŒ– |
| éœ€è¦ä»·å€¼è§‚ | **RL** | å¯é€šè¿‡å¥–åŠ±å‡½æ•°å¯¹é½ |
| å¤æ‚æ¨ç† | SFT + RL | æ··åˆè®­ç»ƒ |

---

## ä¸‹ä¸€æ­¥è®¡åˆ’

**å½“å‰è¿›å±•**ï¼š
- âœ“ MCP åè®®ï¼ˆç¬¬åç« ï¼‰
- âœ“ å¼ºåŒ–å­¦ä¹ ï¼ˆæœ¬ç« ï¼‰

**æ–°éœ€æ±‚**ï¼š
- è¯„ä¼° Agent æ™ºåŠ›æ°´å¹³
- å»ºç«‹æµ‹è¯•åŸºå‡†
- ç§‘å­¦è¡¡é‡æ€§èƒ½

**ä¸‹ä¸€æ­¥ä»»åŠ¡**ï¼š
- [ ] ç¬¬åäºŒç« ï¼šè¯„ä¼°æŒ‡æ ‡ä½“ç³»
- [ ] ç¬¬åäºŒç« ï¼šLLM-as-a-Judge
- [ ] ç¬¬åäºŒç« ï¼šåŸºå‡†æµ‹è¯•

---

## ç³»ç»Ÿæ›´æ–°

```bash
$ git commit -m "feat: add RL training system"

CHANGES:
- æ–°å¢å¥–åŠ±å‡½æ•°æ¨¡å—
- å®ç° GRPO è®­ç»ƒå™¨
- æ·»åŠ ä»·å€¼è§‚å¯¹é½
- ä¿®å¤è¿‡åº¦ä½¿ç”¨æ­¦åŠ›é—®é¢˜

VERSION: 1.0.0
STATUS: Friday ç°åœ¨æœ‰ä»·å€¼è§‚äº†ï¼Œä½†éœ€è¦è¯„ä¼°
```

---

**â†’ [ç¬¬åäºŒç« ï¼šç«æŠ€åœºè€ƒæ ¸](./ç¬¬åäºŒç« ï¼šç«æŠ€åœºè€ƒæ ¸.md)**
