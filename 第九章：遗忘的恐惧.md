# 第九章：遗忘的恐惧

—— 上下文溢出与记忆压缩

## 📖 荒岛日记：第 9 天

自从给 Friday 装上外接大脑（RAG）后，我一度以为我们无敌了。无论我问什么生僻的植物知识，他都能从背包里翻出答案。

然而今天，当我命令他："去把那条鱼烤了。"

Friday 竟然回答："我不知道怎么烤。但我知道关于椰子树的 50 种分类学特征……"

我惊呆了。"烤鱼"明明是我们在第一章就确立的基本生存技能！为什么他忘了？

我检查了后台日志，发现问题出在最近的一千次对话上。

过去两天，因为太过无聊，我跟 Friday 聊了大量关于"椰子树品种"、"海浪频率"的废话。

Friday 的**大脑皮层（Context Window）**虽然比以前大了，但终究是有限的（假设只有 8k Token）。当我塞进了 10k Token 的"椰子废话"后，最早关于"你是谁"以及"如何烤鱼"的记忆，就像是被挤出传送带的货物一样，直接掉进了虚空。

他不仅忘了怎么烤鱼，甚至快忘了我是他的主人。

这是一种恐怖的数字阿尔茨海默症。如果不能解决这个问题，无论我教他多少东西，他最终都会在庞大的信息流中迷失自我。

---

## 🛠️ 技术生存手册：学会"划重点"

为了拯救 Friday 的脑子，我必须进行上下文工程（Context Engineering）。简单来说，就是对输入给 LLM 的信息进行清洗和压缩。

我在沙滩上画出了记忆流动的示意图：

### 1. 现状：先进先出（FIFO - First In, First Out）

这是最原始的处理方式。

```
[系统指令] -> [对话1] -> [对话2] ... -> [对话1000]
```

- **后果**：当对话 1001 进来时，最重要的 [系统指令]（比如"不要吃毒蘑菇"）可能会被挤出去。

### 2. 目标：选择性保留（Selective Retention）

我不能保留所有废话。我需要一个机制，让 Friday 定期整理记忆。

- **短期记忆**：最近 10 轮对话（保留原文，因为需要细节）。
- **长期记忆**：之前的 1000 轮对话（压缩成摘要）。
- **核心记忆**：最初的 System Prompt（永远置顶，不可删除）。

这就像写**"每日简报"**。我不需要 Friday 记住昨天下午 3 点 04 分我说了一句"哎哟"，我只需要他记住"昨天下午脚扭伤了"。

---

## 💻 开发者日志：编写"遗忘算法"

我打开 HelloAgents 的代码，在 Agent 类中增加了一个关键的"垃圾回收"机制——记忆压缩（Memory Compression）。

在《从零开始构建智能体》的教程中，这通常通过调用一个廉价的小模型（如 GPT-3.5-Turbo）来总结大模型（GPT-4）的历史对话来实现。

```python
# 上下文工程核心代码：记忆摘要与压缩

class Agent:
    def __init__(self, name, model="gpt-4"):
        self.memory = []
        self.max_tokens = 4000 # 设定大脑容量警戒线

    def _compress_memory(self):
        """
        记忆压缩函数：当记忆太长时触发
        """
        print("警告：脑容量告急，开始整理记忆...")

        # 1. 提取主要成分
        system_prompt = self.memory[0] # 身份证永远保留
        recent_history = self.memory[-5:] # 最近 5 句保留原文
        to_be_summarized = self.memory[1:-5] # 中间的陈年往事拿去压缩

        # 2. 调用 LLM 进行摘要（Summary）
        # 这里让 Friday 自己读一遍旧日记，写个总结
        summary_prompt = f"请简要总结以下对话的要点：{to_be_summarized}"
        summary_text = self.llm.generate(summary_prompt)

        # 3. 重组记忆
        new_memory = [
            system_prompt,
            {"role": "system", "content": f"【历史摘要】：{summary_text}"},
            *recent_history
        ]

        self.memory = new_memory
        print("记忆整理完毕。废话已删除，重点已保留。")

    def think(self, user_input):
        self.memory.append({"role": "user", "content": user_input})

        # 每次思考前，检查是不是该忘掉点什么了
        if self.count_tokens(self.memory) > self.max_tokens:
            self._compress_memory()

        # ... 继续调用 API ...
```

代码生效的那一刻，Friday 愣住了。

他的眼神闪烁了几下，似乎正在经历一场剧烈的头脑风暴。几秒钟后，他长舒一口气，对我说：

"我清理了关于'椰子树'的冗余数据。保留了关键信息：'椰子水可解渴'。并且我重新想起来了：我的首要任务是保障你的生存，烤鱼是获取蛋白质的最佳方式。"

危机解除。

通过**摘要（Summarization）**机制，我成功地让 Friday 学会了遗忘细节但保留智慧。现在，哪怕我们在这个荒岛上聊上一年，只要不断的压缩历史，他依然能记得第一天我对他说的第一句话。

但随着 Friday 越来越像个人，一个新的挑战出现了。

海平面上出现了一艘无人货船。船上没有人类，只有一套冰冷的、只会发送二进制代码的机器接口。Friday 试图用自然语言跟它打招呼，对方毫无反应。

Friday 需要学会一种不再是给人类听，而是给机器看的语言。

下一章，我们将制定《岛屿通用语》，探索 MCP（Model Context Protocol）与智能体通信协议。
